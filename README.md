# ğŸ“ Text Formalization in the Polish Language

## ğŸ“Œ Project Description

The goal of this project is to create a system that automatically transforms informal Polish utterances into their formal equivalents. Such a tool is particularly useful in academic, professional, and administrative contexts, where maintaining a professional tone is essential.

The solution is based on machine learning â€“ we prepared a synthetic dataset (pairs: informal sentence â€“ formal sentence) used to train and evaluate the language model.

The synthetic corpus was generated using available large language models (LLMs), including instruction-tuned models in chat mode. This enabled the rapid creation of a large number of high-quality linguistic examples, which significantly improved the effectiveness of the fine-tuning process.

The models were trained and evaluated in the Google Colab environment, providing flexibility and easy access to GPU resources. This allowed efficient experimentation without the need to configure a local computing environment.

The trained model is available via a REST API and integrated with a web application built using Streamlit. The user interface also includes a feedback component (thumbs up/down), which stores user ratings in a database.

A detailed description of the experiments (fine-tuning, metrics, model comparisons) is available in the MLflow system:
ğŸ”— [Check the experiments on MLflow](https://dagshub.com/informal2formal/mlflow/experiments)

## ğŸ“„ Dataset
The synthetic dataset used for training and evaluation is publicly available on DagsHub:

ğŸ”— [Check the generated dataset on DagsHub](https://dagshub.com/informal2formal/mlflow/datasets)

It contains pairs of informal and formal Polish sentences generated using instruction-tuned large language models.

---

## ğŸ¤– Hugging Face Model

The final trained model is publicly available on the ğŸ¤— **Hugging Face Hub**:

ğŸ”— [directtt/Llama-PLLuM-8B-instruct-informal2formal-SFT](https://huggingface.co/directtt/Llama-PLLuM-8B-instruct-informal2formal-SFT)

In the repository, you can find the model card with detailed information about the training process, evaluation metrics, and usage instructions.

---

## âš™ï¸ Application Features

- ğŸ”„ Automatic text formalization (from informal to formal)
- ğŸ¤– Hosting of the trained model on Hugging Face Hub
- ğŸŒ REST API integrated with the frontend (Streamlit)
- ğŸ‘ğŸ‘ Feedback component (saves user ratings to a database)
- ğŸ“ˆ Evaluation metrics BLEU / ROUGE available in MLflow
- ğŸ”’ Error handling and input data validation

---

## ğŸš€ Launch Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yanvoi/informal_to_formal_llm.git
cd informal_to_formal_llm
```

### 2. Launch the environment

Instructions for setting up the environment can be found in the `README.md` file in the `app` folder.


ğŸ› ï¸ Note: All Python module versions and dependencies are listed in the pyproject.toml file.

---

## ğŸ“ Project Structure

```
informal_to_formal_llm/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                 # API code
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ ui/                  # Streamlit frontend
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ README.md            # App-specific setup instructions
â”œâ”€â”€ informal_to_formal/
â”‚   â”œâ”€â”€ data_preprocessor/   # Data preprocessing scripts
â”‚   â”œâ”€â”€ evaluation/          # Model evaluation tools
â”‚   â”œâ”€â”€ training/            # Model training scripts
â”‚   â”œâ”€â”€ utils/               # Helper functions
â”‚   â”œâ”€â”€ __init__.py
â”œâ”€â”€ notebooks/               # Jupyter notebooks for experimentation
â”œâ”€â”€ tests/                   # Unit tests
â”œâ”€â”€ pyproject.toml           # Project dependencies and configuration
â”œâ”€â”€ README.md                # Main project README (this file)
```

---

## ğŸ§  Techniques Used

### Few-Shot Prompting
Few-shot prompting was employed to guide the large language models (LLMs) in generating high-quality synthetic data. By providing a few examples of informal-to-formal transformations, the models were able to generalize and produce a diverse set of sentence pairs.

### Fine-Tuning
The LLMs were fine-tuned on the synthetic dataset to specialize in the task of text formalization. This process involved adjusting the pre-trained weights of the models to better align with the specific task requirements.

### Quantization
Quantization techniques were applied to reduce the size of the trained models, making them more efficient for deployment without significant loss in performance. This step was crucial for integrating the models into the web application and REST API.

### Evaluation Metrics
The performance of the models was evaluated using BLEU and ROUGE metrics. These metrics provided insights into the quality of the formalized text compared to the reference sentences.

### Data Augmentation
Synthetic data generation was a key component of the training process. By leveraging instruction-tuned LLMs, a large and diverse dataset was created, which significantly improved the robustness of the models.

---

## ğŸ“„ Authors

- Jan Wojciechowski â€“ 473553  
- Sebastian Jerzykiewicz â€“ 473615  
- JÄ™drzej RybczyÅ„ski â€“ 456532

## ğŸ”š Conclusions

- We did not use the GYAFC corpus, despite our efforts to obtain it, for the following reasons:
  1. Translating it to Polish would have been a significant challenge.
  2. The quality of the corpus was rather poor, with sentences often being ambiguous.

- Unsloth provided a better interface for fine-tuning and utilizing large language models (LLMs), making it our preferred choice.

- The performance of the trained models improved with an increasing number of epochs, but the improvements plateaued after two epochs, showing no significant gains beyond that point.
