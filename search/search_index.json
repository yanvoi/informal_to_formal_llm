{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\ud83d\udcdd Text Formalization in the Polish Language \ud83d\udccc Project Description The goal of this project is to create a system that automatically transforms informal Polish utterances into their formal equivalents. Such a tool is particularly useful in academic, professional, and administrative contexts, where maintaining a professional tone is essential. The solution is based on machine learning \u2013 we prepared a synthetic dataset (pairs: informal sentence \u2013 formal sentence) used to train and evaluate the language model. The synthetic corpus was generated using available large language models (LLMs), including instruction-tuned models in chat mode. This enabled the rapid creation of a large number of high-quality linguistic examples, which significantly improved the effectiveness of the fine-tuning process. The models were trained and evaluated in the Google Colab environment, providing flexibility and easy access to GPU resources. This allowed efficient experimentation without the need to configure a local computing environment. The trained model is available via a REST API and integrated with a web application built using Streamlit. The user interface also includes a feedback component (thumbs up/down), which stores user ratings in a database. A detailed description of the experiments (fine-tuning, metrics, model comparisons) is available in the MLflow system: \ud83d\udd17 Check the experiments on MLflow \ud83d\udcc4 Dataset The synthetic dataset used for training and evaluation is publicly available on DagsHub: \ud83d\udd17 Check the generated dataset on DagsHub It contains pairs of informal and formal Polish sentences generated using instruction-tuned large language models. \ud83e\udd16 Hugging Face Model The final trained model is publicly available on the \ud83e\udd17 Hugging Face Hub : \ud83d\udd17 directtt/Llama-PLLuM-8B-instruct-informal2formal-SFT In the repository, you can find the model card with detailed information about the training process, evaluation metrics, and usage instructions. \u2699\ufe0f Application Features \ud83d\udd04 Automatic text formalization (from informal to formal) \ud83e\udd16 Hosting of the trained model on Hugging Face Hub \ud83c\udf10 REST API integrated with the frontend (Streamlit) \ud83d\udc4d\ud83d\udc4e Feedback component (saves user ratings to a database) \ud83d\udcc8 Evaluation metrics BLEU / ROUGE available in MLflow \ud83d\udd12 Error handling and input data validation \ud83d\ude80 Launch Instructions 1. Clone the repository git clone https://github.com/yanvoi/informal_to_formal_llm.git cd informal_to_formal_llm 2. Launch the environment Instructions for setting up the environment can be found in the README.md file in the app folder. \ud83d\udee0\ufe0f Note: All Python module versions and dependencies are listed in the pyproject.toml file. \ud83d\udcc1 Project Structure informal_to_formal_llm/ \u2502 \u251c\u2500\u2500 app/ \u2502 \u251c\u2500\u2500 api/ # API code \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 main.py \u2502 \u251c\u2500\u2500 ui/ # Streamlit frontend \u2502 \u2502 \u251c\u2500\u2500 main.py \u2502 \u251c\u2500\u2500 README.md # App-specific setup instructions \u251c\u2500\u2500 informal_to_formal/ \u2502 \u251c\u2500\u2500 data_preprocessor/ # Data preprocessing scripts \u2502 \u251c\u2500\u2500 evaluation/ # Model evaluation tools \u2502 \u251c\u2500\u2500 training/ # Model training scripts \u2502 \u251c\u2500\u2500 utils/ # Helper functions \u2502 \u251c\u2500\u2500 __init__.py \u251c\u2500\u2500 notebooks/ # Jupyter notebooks for experimentation \u251c\u2500\u2500 tests/ # Unit tests \u251c\u2500\u2500 pyproject.toml # Project dependencies and configuration \u251c\u2500\u2500 README.md # Main project README (this file) \ud83e\udde0 Techniques Used Few-Shot Prompting Few-shot prompting was employed to guide the large language models (LLMs) in generating high-quality synthetic data. By providing a few examples of informal-to-formal transformations, the models were able to generalize and produce a diverse set of sentence pairs. Fine-Tuning The LLMs were fine-tuned on the synthetic dataset to specialize in the task of text formalization. This process involved adjusting the pre-trained weights of the models to better align with the specific task requirements. Quantization Quantization techniques were applied to reduce the size of the trained models, making them more efficient for deployment without significant loss in performance. This step was crucial for integrating the models into the web application and REST API. Evaluation Metrics The performance of the models was evaluated using BLEU and ROUGE metrics. These metrics provided insights into the quality of the formalized text compared to the reference sentences. Data Augmentation Synthetic data generation was a key component of the training process. By leveraging instruction-tuned LLMs, a large and diverse dataset was created, which significantly improved the robustness of the models. \ud83d\udcc4 Authors Jan Wojciechowski \u2013 473553 Sebastian Jerzykiewicz \u2013 473615 J\u0119drzej Rybczy\u0144ski \u2013 456532 \ud83d\udd1a Conclusions We did not use the GYAFC corpus, despite our efforts to obtain it, for the following reasons: Translating it to Polish would have been a significant challenge. The quality of the corpus was rather poor, with sentences often being ambiguous. Unsloth provided a better interface for fine-tuning and utilizing large language models (LLMs), making it our preferred choice. The performance of the trained models improved with an increasing number of epochs, but the improvements plateaued after two epochs, showing no significant gains beyond that point.","title":"\ud83d\udcdd Text Formalization in the Polish Language"},{"location":"#text-formalization-in-the-polish-language","text":"","title":"\ud83d\udcdd Text Formalization in the Polish Language"},{"location":"#project-description","text":"The goal of this project is to create a system that automatically transforms informal Polish utterances into their formal equivalents. Such a tool is particularly useful in academic, professional, and administrative contexts, where maintaining a professional tone is essential. The solution is based on machine learning \u2013 we prepared a synthetic dataset (pairs: informal sentence \u2013 formal sentence) used to train and evaluate the language model. The synthetic corpus was generated using available large language models (LLMs), including instruction-tuned models in chat mode. This enabled the rapid creation of a large number of high-quality linguistic examples, which significantly improved the effectiveness of the fine-tuning process. The models were trained and evaluated in the Google Colab environment, providing flexibility and easy access to GPU resources. This allowed efficient experimentation without the need to configure a local computing environment. The trained model is available via a REST API and integrated with a web application built using Streamlit. The user interface also includes a feedback component (thumbs up/down), which stores user ratings in a database. A detailed description of the experiments (fine-tuning, metrics, model comparisons) is available in the MLflow system: \ud83d\udd17 Check the experiments on MLflow","title":"\ud83d\udccc Project Description"},{"location":"#dataset","text":"The synthetic dataset used for training and evaluation is publicly available on DagsHub: \ud83d\udd17 Check the generated dataset on DagsHub It contains pairs of informal and formal Polish sentences generated using instruction-tuned large language models.","title":"\ud83d\udcc4 Dataset"},{"location":"#hugging-face-model","text":"The final trained model is publicly available on the \ud83e\udd17 Hugging Face Hub : \ud83d\udd17 directtt/Llama-PLLuM-8B-instruct-informal2formal-SFT In the repository, you can find the model card with detailed information about the training process, evaluation metrics, and usage instructions.","title":"\ud83e\udd16 Hugging Face Model"},{"location":"#application-features","text":"\ud83d\udd04 Automatic text formalization (from informal to formal) \ud83e\udd16 Hosting of the trained model on Hugging Face Hub \ud83c\udf10 REST API integrated with the frontend (Streamlit) \ud83d\udc4d\ud83d\udc4e Feedback component (saves user ratings to a database) \ud83d\udcc8 Evaluation metrics BLEU / ROUGE available in MLflow \ud83d\udd12 Error handling and input data validation","title":"\u2699\ufe0f Application Features"},{"location":"#launch-instructions","text":"","title":"\ud83d\ude80 Launch Instructions"},{"location":"#1-clone-the-repository","text":"git clone https://github.com/yanvoi/informal_to_formal_llm.git cd informal_to_formal_llm","title":"1. Clone the repository"},{"location":"#2-launch-the-environment","text":"Instructions for setting up the environment can be found in the README.md file in the app folder. \ud83d\udee0\ufe0f Note: All Python module versions and dependencies are listed in the pyproject.toml file.","title":"2. Launch the environment"},{"location":"#project-structure","text":"informal_to_formal_llm/ \u2502 \u251c\u2500\u2500 app/ \u2502 \u251c\u2500\u2500 api/ # API code \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 main.py \u2502 \u251c\u2500\u2500 ui/ # Streamlit frontend \u2502 \u2502 \u251c\u2500\u2500 main.py \u2502 \u251c\u2500\u2500 README.md # App-specific setup instructions \u251c\u2500\u2500 informal_to_formal/ \u2502 \u251c\u2500\u2500 data_preprocessor/ # Data preprocessing scripts \u2502 \u251c\u2500\u2500 evaluation/ # Model evaluation tools \u2502 \u251c\u2500\u2500 training/ # Model training scripts \u2502 \u251c\u2500\u2500 utils/ # Helper functions \u2502 \u251c\u2500\u2500 __init__.py \u251c\u2500\u2500 notebooks/ # Jupyter notebooks for experimentation \u251c\u2500\u2500 tests/ # Unit tests \u251c\u2500\u2500 pyproject.toml # Project dependencies and configuration \u251c\u2500\u2500 README.md # Main project README (this file)","title":"\ud83d\udcc1 Project Structure"},{"location":"#techniques-used","text":"","title":"\ud83e\udde0 Techniques Used"},{"location":"#few-shot-prompting","text":"Few-shot prompting was employed to guide the large language models (LLMs) in generating high-quality synthetic data. By providing a few examples of informal-to-formal transformations, the models were able to generalize and produce a diverse set of sentence pairs.","title":"Few-Shot Prompting"},{"location":"#fine-tuning","text":"The LLMs were fine-tuned on the synthetic dataset to specialize in the task of text formalization. This process involved adjusting the pre-trained weights of the models to better align with the specific task requirements.","title":"Fine-Tuning"},{"location":"#quantization","text":"Quantization techniques were applied to reduce the size of the trained models, making them more efficient for deployment without significant loss in performance. This step was crucial for integrating the models into the web application and REST API.","title":"Quantization"},{"location":"#evaluation-metrics","text":"The performance of the models was evaluated using BLEU and ROUGE metrics. These metrics provided insights into the quality of the formalized text compared to the reference sentences.","title":"Evaluation Metrics"},{"location":"#data-augmentation","text":"Synthetic data generation was a key component of the training process. By leveraging instruction-tuned LLMs, a large and diverse dataset was created, which significantly improved the robustness of the models.","title":"Data Augmentation"},{"location":"#authors","text":"Jan Wojciechowski \u2013 473553 Sebastian Jerzykiewicz \u2013 473615 J\u0119drzej Rybczy\u0144ski \u2013 456532","title":"\ud83d\udcc4 Authors"},{"location":"#conclusions","text":"We did not use the GYAFC corpus, despite our efforts to obtain it, for the following reasons: Translating it to Polish would have been a significant challenge. The quality of the corpus was rather poor, with sentences often being ambiguous. Unsloth provided a better interface for fine-tuning and utilizing large language models (LLMs), making it our preferred choice. The performance of the trained models improved with an increasing number of epochs, but the improvements plateaued after two epochs, showing no significant gains beyond that point.","title":"\ud83d\udd1a Conclusions"},{"location":"getting-started/","text":"Getting Started (/app directory) 1. Install Poetry & Make 2. Install dependencies with poetry install 3. Run the API with make run_api 4. Open your browser and go to http://localhost:8000/ 5. Run the UI with make run_ui 6. Open your browser and go to http://localhost:8501/","title":"Getting started"},{"location":"getting-started/#getting-started","text":"(/app directory) 1. Install Poetry & Make 2. Install dependencies with poetry install 3. Run the API with make run_api 4. Open your browser and go to http://localhost:8000/ 5. Run the UI with make run_ui 6. Open your browser and go to http://localhost:8501/","title":"Getting Started"}]}